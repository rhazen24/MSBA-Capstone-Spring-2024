# MSBA-Capstone-Spring-2024
The work done during my group capstone project that took place during my second semester of the MSBA program at the University of Utah in April 2024.

## PROJECT SUMMARY

A substantial portion of the global population faces difficulties securing loans due to inadequate or nonexistent credit histories. These individuals are vulnerable to predatory lending practices, as they are often unable to access safe and fair credit opportunities. Home Credit Group is committed to expanding financial inclusion by providing these underserved populations with a secure and positive borrowing experience. By harnessing a wide array of alternative data, Home Credit not only predicts the repayment abilities of these potential clients more accurately but also ensures that they receive loan terms that are manageable and conducive to financial success.

The primary goal of this project is to enhance the ability of Home Credit Group to predict the repayment capabilities of loan applicants, especially those with limited or no credit history. The traditional reliance on credit history to gauge borrower reliability excludes a significant number of potential clients who may be capable of repayment but lack sufficient credit history. Home Credit Group aims to rectify this by integrating a variety of non-traditional data sources, including telecom and transactional information, into their assessment processes.

## OUR GROUP'S SOLUTION

In order to resolve this issue, through constant iteration and trial and error, we landed on a Gradiant Boosting model in order to predict whether a borrower would be able to repay or default on their loan. Gradient boosting is well known for its high predictive accuracy and ability to handle non-linear relationships between variables, making it suitable for the complex patterns often found in financial datasets. It's also less sensitive to outliers, which ensures that extreme values do not skew the predictions.

This model's capability to provide a ranking of feature importance is crucial for understanding which factors are most predictive of a default, enabling Home Credit to make informed decisions and tailor their financial products more effectively. Moreover, gradient boosting can be customized with different loss functions to focus on specific aspects of the prediction—such as minimizing false negatives—which is vital given the severe implications of incorrectly predicting a loan default. The model's robustness and adaptability make it an indispensable tool in our efforts to enhance financial inclusion, ensuring that reliable borrowers aren't unjustly denied loans due to a lack of credit history. By leveraging such a powerful predictive tool, Home Credit can extend their services to a broader audience while managing risk effectively, aligning with their mission to empower customers and promote equitable financial access.

## MY CONTRIBUTION TO THE PROJECT

After spending time going through everyone's individual exploratory data analysis and sharing ideas and insights, it came time to actually build models. We spent time working in the same workbook and would send any updates to the group when they were made individually. Personally, I spent a lot of time working on the random forest and gradiant boosting models we were deciding between. My contribution consisted of debugging, utilizing one-hot encoding so our categorical variables could be better used in the model, feature engineering for both models, and collaborating with the group and sharing ideas when we hit a snag trying to get any sort of model outputs. I also spent time working on the slides when preparing our presentation.

## SOLUTION BUSINESS VALUE ADDED

The implementation of a gradient boosting model significantly enhances Home Credit's ability to extend loans more inclusively and responsibly. By accurately predicting the probability of loan repayments, this model helps enable Home Credit to serve a broader segment of potential customers who may lack traditional credit histories. This expansion not only grows Home Credit's customer base but also supports its mission of promoting financial inclusion. Additionally, the decent accuracy of gradient boosting models in predicting defaults minimizes financial risks, reducing the incidence of non-repayment and associated losses. This is vital for maintaining the financial sustainability of the company.

Furthermore, the operational efficiencies gained from leveraging such advanced analytics allow for faster and more cost-effective loan processing, reducing the need for extensive manual reviews and accelerating the loan approval process. The insights gained from the model also aid in developing tailored financial products that meet the specific needs of different customer segments, enhancing customer satisfaction and loyalty. Overall, by implementing this predictive tool, Home Credit not only enhances its competitive edge in the market but also strengthens its reputation as an innovative leader committed to ethical lending practices and empowerment of the underserved.

## GROUP DIFFICULTIES

Some of the difficulties we faced as a group included working with the categorical variables. We spent a lot of time debugging because our categorical variables weren't being encoded properly as factors. This is when the one-hot encoding was introduced. However, we discovered that the issues were rooted in the way that we merged our train dataset as well as the previous application dataset. We would set the categorical variables as factors when the train set was first loaded and would perform data cleaning on that set. Later on, when the previous application dataset was introduced and merged, the variables would revert back to object data types. When we finally resolved this issue, we were able to get model outputs. 

Our model accuracy wasn't outstanding. Our AUC for the Kaggle submission was a 65%. We figured this was due to model overfitting and the model being introduced to too much noise too quickly. If we were to do it over again, we would tune our parameters and teach the model more slowly among other adjustments.

## PROJECT TAKEAWAYS

Going through an entire process of being introduced a business problem, performing an EDA, modeling, and presenting to a business in a sandbox environment was extremely valuable. Though the data was from a Kaggle competiton, this is the dirtiest and largest dataset I've had the opportunity of working with up to this point. With that, there were a lot of challenges trying to sift through the noise and discovering the truly valuable information. If I were to do this project over, I would have interacted with some of the other datasets made available to us in order to better train our model. We limited ourselves only working with the previous application dataset. It was a good start, but I think grabbing other, stronger features from other datasets would have taught our model better.

I also want to improve at being more thorough in my EDA process and making sure I go through all of the information available to me to better set myself up for success when it comes time for modeling. I also learned a ton about working with a group and communicating effectively with them. Schedules aren't always going to line up perfectly but it takes sacrifices to meet deadlines.
